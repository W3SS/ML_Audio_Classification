{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Notebook initialization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def load_features(directory):\n",
    "    au_features = pd.read_csv('{}/{}/audio_features.csv'.format('../data/output/features',directory), index_col=0)\n",
    "    im_features = pd.read_csv('{}/{}/image_features.csv'.format('../data/output/features',directory), index_col=0)\n",
    "    \n",
    "    # Drop redundant columns\n",
    "    im_features = im_features.drop(['label'], axis=1)\n",
    "\n",
    "    # Merge audio and image features\n",
    "    features = pd.concat([au_features, im_features], axis=1)\n",
    "\n",
    "    # Only look at clips less than 300s long\n",
    "    features = features[features.length < 300]\n",
    "    \n",
    "    return features"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Labeled audios"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Import data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>audio_file</th>\n",
       "      <th>image_file</th>\n",
       "      <th>length</th>\n",
       "      <th>label</th>\n",
       "      <th>percent_silence</th>\n",
       "      <th>ring_count</th>\n",
       "      <th>last_ring_to_end</th>\n",
       "      <th>white_proportion</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>index</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>/Users/jjelosua/Developer/lanacion/ML_audio_cl...</td>\n",
       "      <td>/Users/jjelosua/Developer/lanacion/ML_audio_cl...</td>\n",
       "      <td>52.740</td>\n",
       "      <td>0</td>\n",
       "      <td>0.342474</td>\n",
       "      <td>0</td>\n",
       "      <td>52.704000</td>\n",
       "      <td>0.831465</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>/Users/jjelosua/Developer/lanacion/ML_audio_cl...</td>\n",
       "      <td>/Users/jjelosua/Developer/lanacion/ML_audio_cl...</td>\n",
       "      <td>27.000</td>\n",
       "      <td>1</td>\n",
       "      <td>0.958180</td>\n",
       "      <td>0</td>\n",
       "      <td>26.928000</td>\n",
       "      <td>0.977077</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>/Users/jjelosua/Developer/lanacion/ML_audio_cl...</td>\n",
       "      <td>/Users/jjelosua/Developer/lanacion/ML_audio_cl...</td>\n",
       "      <td>56.088</td>\n",
       "      <td>0</td>\n",
       "      <td>0.208273</td>\n",
       "      <td>0</td>\n",
       "      <td>56.016000</td>\n",
       "      <td>0.853612</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>/Users/jjelosua/Developer/lanacion/ML_audio_cl...</td>\n",
       "      <td>/Users/jjelosua/Developer/lanacion/ML_audio_cl...</td>\n",
       "      <td>215.640</td>\n",
       "      <td>0</td>\n",
       "      <td>0.122387</td>\n",
       "      <td>0</td>\n",
       "      <td>215.568000</td>\n",
       "      <td>0.823863</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>/Users/jjelosua/Developer/lanacion/ML_audio_cl...</td>\n",
       "      <td>/Users/jjelosua/Developer/lanacion/ML_audio_cl...</td>\n",
       "      <td>117.216</td>\n",
       "      <td>0</td>\n",
       "      <td>0.407660</td>\n",
       "      <td>2</td>\n",
       "      <td>107.154625</td>\n",
       "      <td>0.880819</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                              audio_file  \\\n",
       "index                                                      \n",
       "0      /Users/jjelosua/Developer/lanacion/ML_audio_cl...   \n",
       "1      /Users/jjelosua/Developer/lanacion/ML_audio_cl...   \n",
       "2      /Users/jjelosua/Developer/lanacion/ML_audio_cl...   \n",
       "3      /Users/jjelosua/Developer/lanacion/ML_audio_cl...   \n",
       "4      /Users/jjelosua/Developer/lanacion/ML_audio_cl...   \n",
       "\n",
       "                                              image_file   length  label  \\\n",
       "index                                                                      \n",
       "0      /Users/jjelosua/Developer/lanacion/ML_audio_cl...   52.740      0   \n",
       "1      /Users/jjelosua/Developer/lanacion/ML_audio_cl...   27.000      1   \n",
       "2      /Users/jjelosua/Developer/lanacion/ML_audio_cl...   56.088      0   \n",
       "3      /Users/jjelosua/Developer/lanacion/ML_audio_cl...  215.640      0   \n",
       "4      /Users/jjelosua/Developer/lanacion/ML_audio_cl...  117.216      0   \n",
       "\n",
       "       percent_silence  ring_count  last_ring_to_end  white_proportion  \n",
       "index                                                                   \n",
       "0             0.342474           0         52.704000          0.831465  \n",
       "1             0.958180           0         26.928000          0.977077  \n",
       "2             0.208273           0         56.016000          0.853612  \n",
       "3             0.122387           0        215.568000          0.823863  \n",
       "4             0.407660           2        107.154625          0.880819  "
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "features = load_features('train')\n",
    "features.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data Preparation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Clean Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>audio_file</th>\n",
       "      <th>image_file</th>\n",
       "      <th>length</th>\n",
       "      <th>label</th>\n",
       "      <th>percent_silence</th>\n",
       "      <th>ring_count</th>\n",
       "      <th>last_ring_to_end</th>\n",
       "      <th>white_proportion</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>index</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>14274</th>\n",
       "      <td>/Users/jjelosua/Developer/lanacion/ML_audio_cl...</td>\n",
       "      <td>/Users/jjelosua/Developer/lanacion/ML_audio_cl...</td>\n",
       "      <td>84.24</td>\n",
       "      <td>1</td>\n",
       "      <td>0.003811</td>\n",
       "      <td>0</td>\n",
       "      <td>84.168</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                              audio_file  \\\n",
       "index                                                      \n",
       "14274  /Users/jjelosua/Developer/lanacion/ML_audio_cl...   \n",
       "\n",
       "                                              image_file  length  label  \\\n",
       "index                                                                     \n",
       "14274  /Users/jjelosua/Developer/lanacion/ML_audio_cl...   84.24      1   \n",
       "\n",
       "       percent_silence  ring_count  last_ring_to_end  white_proportion  \n",
       "index                                                                   \n",
       "14274         0.003811           0            84.168               NaN  "
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(len(features[features.isnull().any(axis=1)]))\n",
    "features[features.isnull().any(axis=1)].head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# just drop the remaning rows with nan values\n",
    "features = features.dropna()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Split training and test set\n",
    "from sklearn import cross_validation\n",
    "columns = ['label', 'length', 'last_ring_to_end', 'percent_silence', 'ring_count', 'white_proportion']\n",
    "train, test = cross_validation.train_test_split(features[columns], train_size=0.7, random_state=1000)\n",
    "y_train = train['label']\n",
    "X_train = train.drop('label', axis=1)\n",
    "y_test = test['label']\n",
    "X_test = test.drop('label', axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Scale features\n",
    "from sklearn import preprocessing\n",
    "scaler = preprocessing.StandardScaler().fit(X_train)\n",
    "X_train_scaled = scaler.transform(X_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Fit Models"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Logistic Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('length', -3.814302896584862),\n",
       " ('last_ring_to_end', 0.0056240364270560934),\n",
       " ('percent_silence', -0.67390678402142834),\n",
       " ('ring_count', 0.48483923341906693),\n",
       " ('white_proportion', 2.3131580570928114)]"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "lr = LogisticRegression()\n",
    "lr.fit(X_train_scaled, y_train)\n",
    "list(zip(columns[1:], lr.coef_[0]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Random Forest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('length', 0.30593363755717351),\n",
       " ('last_ring_to_end', 0.33353202776482688),\n",
       " ('percent_silence', 0.15206534339705702),\n",
       " ('ring_count', 0.0086084243372190443),\n",
       " ('white_proportion', 0.19986056694372359)]"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier\n",
    "rf = RandomForestClassifier(n_estimators=15, n_jobs=-1)\n",
    "rf.fit(X_train_scaled, y_train)\n",
    "list(zip(columns[1:], rf.feature_importances_))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Support Vector classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "SVC(C=1.0, cache_size=200, class_weight=None, coef0=0.0,\n",
       "  decision_function_shape=None, degree=3, gamma='auto', kernel='rbf',\n",
       "  max_iter=-1, probability=True, random_state=None, shrinking=True,\n",
       "  tol=0.001, verbose=False)"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.svm import SVC\n",
    "svm = SVC(kernel='rbf', probability=True) # available kernels: linear, poly, rbf, sigmoid\n",
    "svm.fit(X_train_scaled, y_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model Predictions on test set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.892425845961\n",
      "0.909617553453\n",
      "0.913974904845\n"
     ]
    }
   ],
   "source": [
    "## Predict on the test set\n",
    "from sklearn import metrics\n",
    "for m in [lr, rf, svm]:\n",
    "    X_test_scaled = scaler.transform(X_test)\n",
    "    y_pred = m.predict(X_test_scaled)\n",
    "    # Area under the curve\n",
    "    # http://scikit-learn.org/stable/modules/generated/sklearn.metrics.roc_auc_score.html\n",
    "    print(metrics.roc_auc_score(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Test each model with different metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LogisticRegression\n",
      "\troc_auc: 0.96 (+/- 0.02)\n",
      "\taverage_precision: 0.94 (+/- 0.03)\n",
      "\trecall: 0.90 (+/- 0.04)\n",
      "\tf1: 0.88 (+/- 0.03)\n",
      "RandomForestClassifier\n",
      "\troc_auc: 0.96 (+/- 0.02)\n",
      "\taverage_precision: 0.95 (+/- 0.02)\n",
      "\trecall: 0.89 (+/- 0.04)\n",
      "\tf1: 0.90 (+/- 0.03)\n",
      "SVC\n",
      "\troc_auc: 0.96 (+/- 0.02)\n",
      "\taverage_precision: 0.94 (+/- 0.03)\n",
      "\trecall: 0.91 (+/- 0.04)\n",
      "\tf1: 0.90 (+/- 0.02)\n"
     ]
    }
   ],
   "source": [
    "from sklearn.pipeline import make_pipeline\n",
    "# Features to use\n",
    "columns = ['length', 'ring_count', 'last_ring_to_end', 'percent_silence', 'white_proportion']\n",
    "\n",
    "X = features[columns]\n",
    "y = features['label']\n",
    "\n",
    "for m in [LogisticRegression(),RandomForestClassifier(n_estimators=20, n_jobs=-1), SVC(kernel='rbf')]:\n",
    "    # First scale and then apply model\n",
    "    clf = make_pipeline(preprocessing.StandardScaler(), m)\n",
    "    print(m.__class__.__name__)\n",
    "    \n",
    "    # options for scoring: http://scikit-learn.org/stable/modules/model_evaluation.html#scoring-parameter\n",
    "    for scorer in ['roc_auc', 'average_precision', 'recall', 'f1']:\n",
    "        scores = cross_validation.cross_val_score(clf, X, y, cv=10, scoring=scorer, n_jobs=-1)\n",
    "        print(\"\\t{}: {:.2f} (+/- {:.2f})\".format(scorer, scores.mean(), scores.std() * 2))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Unlabeled Audios"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>audio_file</th>\n",
       "      <th>image_file</th>\n",
       "      <th>length</th>\n",
       "      <th>label</th>\n",
       "      <th>percent_silence</th>\n",
       "      <th>ring_count</th>\n",
       "      <th>last_ring_to_end</th>\n",
       "      <th>white_proportion</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>index</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>/Users/jjelosua/Developer/lanacion/ML_audio_cl...</td>\n",
       "      <td>/Users/jjelosua/Developer/lanacion/ML_audio_cl...</td>\n",
       "      <td>55.800</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.376077</td>\n",
       "      <td>2</td>\n",
       "      <td>43.251875</td>\n",
       "      <td>0.880129</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>/Users/jjelosua/Developer/lanacion/ML_audio_cl...</td>\n",
       "      <td>/Users/jjelosua/Developer/lanacion/ML_audio_cl...</td>\n",
       "      <td>65.880</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.357495</td>\n",
       "      <td>0</td>\n",
       "      <td>65.808000</td>\n",
       "      <td>0.838058</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>/Users/jjelosua/Developer/lanacion/ML_audio_cl...</td>\n",
       "      <td>/Users/jjelosua/Developer/lanacion/ML_audio_cl...</td>\n",
       "      <td>9.576</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.072220</td>\n",
       "      <td>0</td>\n",
       "      <td>9.504000</td>\n",
       "      <td>0.890358</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>/Users/jjelosua/Developer/lanacion/ML_audio_cl...</td>\n",
       "      <td>/Users/jjelosua/Developer/lanacion/ML_audio_cl...</td>\n",
       "      <td>5.256</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.421754</td>\n",
       "      <td>0</td>\n",
       "      <td>5.184000</td>\n",
       "      <td>0.910165</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>/Users/jjelosua/Developer/lanacion/ML_audio_cl...</td>\n",
       "      <td>/Users/jjelosua/Developer/lanacion/ML_audio_cl...</td>\n",
       "      <td>5.760</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.471123</td>\n",
       "      <td>0</td>\n",
       "      <td>5.688000</td>\n",
       "      <td>0.910035</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                              audio_file  \\\n",
       "index                                                      \n",
       "0      /Users/jjelosua/Developer/lanacion/ML_audio_cl...   \n",
       "1      /Users/jjelosua/Developer/lanacion/ML_audio_cl...   \n",
       "2      /Users/jjelosua/Developer/lanacion/ML_audio_cl...   \n",
       "3      /Users/jjelosua/Developer/lanacion/ML_audio_cl...   \n",
       "4      /Users/jjelosua/Developer/lanacion/ML_audio_cl...   \n",
       "\n",
       "                                              image_file  length  label  \\\n",
       "index                                                                     \n",
       "0      /Users/jjelosua/Developer/lanacion/ML_audio_cl...  55.800    NaN   \n",
       "1      /Users/jjelosua/Developer/lanacion/ML_audio_cl...  65.880    NaN   \n",
       "2      /Users/jjelosua/Developer/lanacion/ML_audio_cl...   9.576    NaN   \n",
       "3      /Users/jjelosua/Developer/lanacion/ML_audio_cl...   5.256    NaN   \n",
       "4      /Users/jjelosua/Developer/lanacion/ML_audio_cl...   5.760    NaN   \n",
       "\n",
       "       percent_silence  ring_count  last_ring_to_end  white_proportion  \n",
       "index                                                                   \n",
       "0             0.376077           2         43.251875          0.880129  \n",
       "1             0.357495           0         65.808000          0.838058  \n",
       "2             0.072220           0          9.504000          0.890358  \n",
       "3             0.421754           0          5.184000          0.910165  \n",
       "4             0.471123           0          5.688000          0.910035  "
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "unl_features = load_features('test')\n",
    "unl_features.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Clean data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Get rid of label column\n",
    "unl_features = unl_features.drop('label', axis=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Check data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>audio_file</th>\n",
       "      <th>image_file</th>\n",
       "      <th>length</th>\n",
       "      <th>percent_silence</th>\n",
       "      <th>ring_count</th>\n",
       "      <th>last_ring_to_end</th>\n",
       "      <th>white_proportion</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>index</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>9746</th>\n",
       "      <td>/Users/jjelosua/Developer/lanacion/ML_audio_cl...</td>\n",
       "      <td>/Users/jjelosua/Developer/lanacion/ML_audio_cl...</td>\n",
       "      <td>29.664</td>\n",
       "      <td>0.014239</td>\n",
       "      <td>0</td>\n",
       "      <td>29.592000</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12398</th>\n",
       "      <td>/Users/jjelosua/Developer/lanacion/ML_audio_cl...</td>\n",
       "      <td>/Users/jjelosua/Developer/lanacion/ML_audio_cl...</td>\n",
       "      <td>88.560</td>\n",
       "      <td>0.020017</td>\n",
       "      <td>2</td>\n",
       "      <td>49.359125</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                              audio_file  \\\n",
       "index                                                      \n",
       "9746   /Users/jjelosua/Developer/lanacion/ML_audio_cl...   \n",
       "12398  /Users/jjelosua/Developer/lanacion/ML_audio_cl...   \n",
       "\n",
       "                                              image_file  length  \\\n",
       "index                                                              \n",
       "9746   /Users/jjelosua/Developer/lanacion/ML_audio_cl...  29.664   \n",
       "12398  /Users/jjelosua/Developer/lanacion/ML_audio_cl...  88.560   \n",
       "\n",
       "       percent_silence  ring_count  last_ring_to_end  white_proportion  \n",
       "index                                                                   \n",
       "9746          0.014239           0         29.592000               NaN  \n",
       "12398         0.020017           2         49.359125               NaN  "
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Take a look at where nan values are\n",
    "print(len(unl_features[unl_features.isnull().any(axis=1)]))\n",
    "unl_features[unl_features.isnull().any(axis=1)].head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# just drop the remaning rows with nan values\n",
    "unl_features = unl_features.dropna()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Reset index after cleanup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>audio_file</th>\n",
       "      <th>image_file</th>\n",
       "      <th>length</th>\n",
       "      <th>percent_silence</th>\n",
       "      <th>ring_count</th>\n",
       "      <th>last_ring_to_end</th>\n",
       "      <th>white_proportion</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>/Users/jjelosua/Developer/lanacion/ML_audio_cl...</td>\n",
       "      <td>/Users/jjelosua/Developer/lanacion/ML_audio_cl...</td>\n",
       "      <td>55.800</td>\n",
       "      <td>0.376077</td>\n",
       "      <td>2</td>\n",
       "      <td>43.251875</td>\n",
       "      <td>0.880129</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>/Users/jjelosua/Developer/lanacion/ML_audio_cl...</td>\n",
       "      <td>/Users/jjelosua/Developer/lanacion/ML_audio_cl...</td>\n",
       "      <td>65.880</td>\n",
       "      <td>0.357495</td>\n",
       "      <td>0</td>\n",
       "      <td>65.808000</td>\n",
       "      <td>0.838058</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>/Users/jjelosua/Developer/lanacion/ML_audio_cl...</td>\n",
       "      <td>/Users/jjelosua/Developer/lanacion/ML_audio_cl...</td>\n",
       "      <td>9.576</td>\n",
       "      <td>0.072220</td>\n",
       "      <td>0</td>\n",
       "      <td>9.504000</td>\n",
       "      <td>0.890358</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>/Users/jjelosua/Developer/lanacion/ML_audio_cl...</td>\n",
       "      <td>/Users/jjelosua/Developer/lanacion/ML_audio_cl...</td>\n",
       "      <td>5.256</td>\n",
       "      <td>0.421754</td>\n",
       "      <td>0</td>\n",
       "      <td>5.184000</td>\n",
       "      <td>0.910165</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>/Users/jjelosua/Developer/lanacion/ML_audio_cl...</td>\n",
       "      <td>/Users/jjelosua/Developer/lanacion/ML_audio_cl...</td>\n",
       "      <td>5.760</td>\n",
       "      <td>0.471123</td>\n",
       "      <td>0</td>\n",
       "      <td>5.688000</td>\n",
       "      <td>0.910035</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                          audio_file  \\\n",
       "0  /Users/jjelosua/Developer/lanacion/ML_audio_cl...   \n",
       "1  /Users/jjelosua/Developer/lanacion/ML_audio_cl...   \n",
       "2  /Users/jjelosua/Developer/lanacion/ML_audio_cl...   \n",
       "3  /Users/jjelosua/Developer/lanacion/ML_audio_cl...   \n",
       "4  /Users/jjelosua/Developer/lanacion/ML_audio_cl...   \n",
       "\n",
       "                                          image_file  length  percent_silence  \\\n",
       "0  /Users/jjelosua/Developer/lanacion/ML_audio_cl...  55.800         0.376077   \n",
       "1  /Users/jjelosua/Developer/lanacion/ML_audio_cl...  65.880         0.357495   \n",
       "2  /Users/jjelosua/Developer/lanacion/ML_audio_cl...   9.576         0.072220   \n",
       "3  /Users/jjelosua/Developer/lanacion/ML_audio_cl...   5.256         0.421754   \n",
       "4  /Users/jjelosua/Developer/lanacion/ML_audio_cl...   5.760         0.471123   \n",
       "\n",
       "   ring_count  last_ring_to_end  white_proportion  \n",
       "0           2         43.251875          0.880129  \n",
       "1           0         65.808000          0.838058  \n",
       "2           0          9.504000          0.890358  \n",
       "3           0          5.184000          0.910165  \n",
       "4           0          5.688000          0.910035  "
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# reset index for concatenating predicted labels\n",
    "unl_features = unl_features.reset_index(drop=True)\n",
    "unl_features.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Selected models \n",
    "models = [\n",
    "    LogisticRegression(),\n",
    "    RandomForestClassifier(n_estimators=20, n_jobs=-1),\n",
    "    SVC(kernel='rbf', probability=True),\n",
    "]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data preparation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Features to use\n",
    "columns = ['length', 'ring_count', 'last_ring_to_end', 'percent_silence', 'white_proportion']\n",
    "\n",
    "y_train_all = features['label']\n",
    "X_train_all = features[columns]\n",
    "\n",
    "# Scale features\n",
    "scaler = preprocessing.StandardScaler()\n",
    "X_train_all_scaled = scaler.fit_transform(X_train_all)\n",
    "unl_features_scaled = scaler.transform(unl_features[columns])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training LogisticRegression\n",
      "Training RandomForestClassifier\n",
      "Training SVC\n"
     ]
    }
   ],
   "source": [
    "# Balanced predicted labels \n",
    "labels_pred = []\n",
    "# Probability distribution to minimize false positives (discarded)\n",
    "proba_pred = []\n",
    "# Fit model and predict for unlabeled data\n",
    "for m in models:\n",
    "    print('Training', m.__class__.__name__)\n",
    "    m.fit(X_train_all_scaled, y_train_all)\n",
    "    labels_pred.append(m.predict(unl_features_scaled))\n",
    "    proba_pred.append(m.predict_proba(unl_features_scaled))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Balanced labels analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(array([0, 1]), array([10313,  8657]))\n",
      "(array([0, 1]), array([11031,  7939]))\n",
      "(array([0, 1]), array([10793,  8177]))\n"
     ]
    }
   ],
   "source": [
    "for labels in labels_pred:\n",
    "    print(np.unique(labels, return_counts=True))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Combine predictions from models to assign the final labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Combine labels from each predictor into a matrix (one row per predictor)\n",
    "agg_labels = np.vstack(labels_pred)\n",
    "# Sum each column of labels\n",
    "al = np.sum(agg_labels, axis=0)\n",
    "\n",
    "# If at least two predictors predict \"1\", then \"1\", else \"0\"\n",
    "al[np.where(al <= 1)] = 0\n",
    "al[np.where(al > 1)] = 1\n",
    "final_labels = al"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array([0, 1]), array([10744,  8226]))"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.unique(final_labels, return_counts=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Unbalanced labels analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# False positive threshold\n",
    "threshold = 0.9\n",
    "labels_pred_unbalanced = []\n",
    "for proba in proba_pred:\n",
    "    labels_model = []\n",
    "    for p0, p1 in proba:\n",
    "        label = 1 if p1 >= threshold else 0\n",
    "        labels_model.append(label)\n",
    "    labels_pred_unbalanced.append(labels_model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(array([0, 1]), array([15686,  3284]))\n",
      "(array([0, 1]), array([13154,  5816]))\n",
      "(array([0, 1]), array([14053,  4917]))\n"
     ]
    }
   ],
   "source": [
    "for labels in labels_pred_unbalanced:\n",
    "    print(np.unique(labels, return_counts=True))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Combine predictions from models to assign the final labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Combine labels from each predictor into a matrix (one row per predictor)\n",
    "agg_labels = np.vstack(labels_pred_unbalanced)\n",
    "# Sum each column of labels\n",
    "al = np.sum(agg_labels, axis=0)\n",
    "\n",
    "# If at least two predictors predict \"1\", then \"1\", else \"0\"\n",
    "al[np.where(al <= 1)] = 0\n",
    "al[np.where(al > 1)] = 1\n",
    "final_labels_unb = al"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array([0, 1]), array([13625,  5345]))"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.unique(final_labels_unb, return_counts=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>pred_label</th>\n",
       "      <th>pred_label90</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   pred_label  pred_label90\n",
       "0           0             0\n",
       "1           0             0\n",
       "2           1             1\n",
       "3           1             1\n",
       "4           1             1"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Create a dataFrame for the predicted labels\n",
    "pred_labels = pd.DataFrame(final_labels, columns=['pred_label'])\n",
    "pred_labels_unb = pd.DataFrame(final_labels_unb, columns=['pred_label90'])\n",
    "predicted_labels = pd.concat([pred_labels, pred_labels_unb], axis=1)\n",
    "predicted_labels.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>audio_file</th>\n",
       "      <th>image_file</th>\n",
       "      <th>length</th>\n",
       "      <th>percent_silence</th>\n",
       "      <th>ring_count</th>\n",
       "      <th>last_ring_to_end</th>\n",
       "      <th>white_proportion</th>\n",
       "      <th>pred_label</th>\n",
       "      <th>pred_label90</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>/Users/jjelosua/Developer/lanacion/ML_audio_cl...</td>\n",
       "      <td>/Users/jjelosua/Developer/lanacion/ML_audio_cl...</td>\n",
       "      <td>55.800</td>\n",
       "      <td>0.376077</td>\n",
       "      <td>2</td>\n",
       "      <td>43.251875</td>\n",
       "      <td>0.880129</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>/Users/jjelosua/Developer/lanacion/ML_audio_cl...</td>\n",
       "      <td>/Users/jjelosua/Developer/lanacion/ML_audio_cl...</td>\n",
       "      <td>65.880</td>\n",
       "      <td>0.357495</td>\n",
       "      <td>0</td>\n",
       "      <td>65.808000</td>\n",
       "      <td>0.838058</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>/Users/jjelosua/Developer/lanacion/ML_audio_cl...</td>\n",
       "      <td>/Users/jjelosua/Developer/lanacion/ML_audio_cl...</td>\n",
       "      <td>9.576</td>\n",
       "      <td>0.072220</td>\n",
       "      <td>0</td>\n",
       "      <td>9.504000</td>\n",
       "      <td>0.890358</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>/Users/jjelosua/Developer/lanacion/ML_audio_cl...</td>\n",
       "      <td>/Users/jjelosua/Developer/lanacion/ML_audio_cl...</td>\n",
       "      <td>5.256</td>\n",
       "      <td>0.421754</td>\n",
       "      <td>0</td>\n",
       "      <td>5.184000</td>\n",
       "      <td>0.910165</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>/Users/jjelosua/Developer/lanacion/ML_audio_cl...</td>\n",
       "      <td>/Users/jjelosua/Developer/lanacion/ML_audio_cl...</td>\n",
       "      <td>5.760</td>\n",
       "      <td>0.471123</td>\n",
       "      <td>0</td>\n",
       "      <td>5.688000</td>\n",
       "      <td>0.910035</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                          audio_file  \\\n",
       "0  /Users/jjelosua/Developer/lanacion/ML_audio_cl...   \n",
       "1  /Users/jjelosua/Developer/lanacion/ML_audio_cl...   \n",
       "2  /Users/jjelosua/Developer/lanacion/ML_audio_cl...   \n",
       "3  /Users/jjelosua/Developer/lanacion/ML_audio_cl...   \n",
       "4  /Users/jjelosua/Developer/lanacion/ML_audio_cl...   \n",
       "\n",
       "                                          image_file  length  percent_silence  \\\n",
       "0  /Users/jjelosua/Developer/lanacion/ML_audio_cl...  55.800         0.376077   \n",
       "1  /Users/jjelosua/Developer/lanacion/ML_audio_cl...  65.880         0.357495   \n",
       "2  /Users/jjelosua/Developer/lanacion/ML_audio_cl...   9.576         0.072220   \n",
       "3  /Users/jjelosua/Developer/lanacion/ML_audio_cl...   5.256         0.421754   \n",
       "4  /Users/jjelosua/Developer/lanacion/ML_audio_cl...   5.760         0.471123   \n",
       "\n",
       "   ring_count  last_ring_to_end  white_proportion  pred_label  pred_label90  \n",
       "0           2         43.251875          0.880129           0             0  \n",
       "1           0         65.808000          0.838058           0             0  \n",
       "2           0          9.504000          0.890358           1             1  \n",
       "3           0          5.184000          0.910165           1             1  \n",
       "4           0          5.688000          0.910035           1             1  "
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "unlabeled_final = pd.concat([unl_features, predicted_labels], axis=1)\n",
    "unlabeled_final.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Export data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import os\n",
    "export_path = '../data/output/predicted'\n",
    "if not os.path.exists(export_path):\n",
    "    os.makedirs(export_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "unlabeled_final.to_csv('{}/unlabeled_predicted.csv'.format(export_path), index_label='index')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.4.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
